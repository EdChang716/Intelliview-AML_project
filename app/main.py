from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, FileResponse, Response
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi import WebSocket, WebSocketDisconnect
from fastapi.responses import StreamingResponse
from io import BytesIO
import websockets
import aiohttp

from pydantic import BaseModel
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone
import json, os
import sys, random
import shutil
import asyncio
from tempfile import NamedTemporaryFile


from parsers.resume_parser import (
    extract_pdf_text,
    parse_resume_entries,
    extract_metadata_sections,
    extract_structured_education,
)
from core.embeddings import build_resume_embeddings

from core.llm_client import client
#client = OpenAI(api_key=os.getenv("OPENAI_API_KEY", "your_API_key"))

# from the module I built
from core.config import BASE_DIR, USER_DATA_DIR
from core.llm_client import client
from core.profiles import (
    load_job_profiles,
    save_job_profiles,
    load_all_profiles as _load_all_profiles_from_core,
)
from core.retrieval import (
    retrieve_bullets_for_profile,
    get_bullets_for_entry,
    load_resume_entries_and_embs,
)
from core.sessions import (
    load_session,
    get_asked_questions,
    log_practice_turn,
    log_asked_question,
    get_practice_stats,
)
from core.questions import (
    call_llm_for_question,
    get_behavioral_question,
    call_llm_for_project_question,
    generate_followup_question,
)
from core.answers import (
    call_llm_for_sample_answer,
    evaluate_answer,
)

from core.transcription import transcribe_media
from core import mock_interview
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

APP_DIR = Path(__file__).resolve().parent
ROOT_DIR = APP_DIR  # ä½ çš„å°ˆæ¡ˆæ ¹ç›®éŒ„
sys.path.append(str(ROOT_DIR))

USER_DATA_DIR.mkdir(exist_ok=True)
JOB_PROFILES_PATH = USER_DATA_DIR / "job_profiles.json"
SESSION_MEDIA_DIR = USER_DATA_DIR / "session_media"
SESSION_MEDIA_DIR.mkdir(parents=True, exist_ok=True)

app = FastAPI(title="Intelliview Coach")

# static / templates
app.mount("/static", StaticFiles(directory=APP_DIR / "static"), name="static")
templates = Jinja2Templates(directory=str(APP_DIR / "templates"))
timestamp = datetime.now(timezone.utc).isoformat()
now = datetime.utcnow().isoformat() + "Z"

def save_job_profiles(profiles: list[dict]) -> None:
    JOB_PROFILES_PATH.parent.mkdir(parents=True, exist_ok=True)
    JOB_PROFILES_PATH.write_text(
        json.dumps({"profiles": profiles}, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )

# =========================
# è·¯å¾‘è¨­å®šï¼ˆä»¥ä¸‹ä¿ç•™ä½ åŸæœ¬çš„å¯«æ³•ï¼Œå¯¦éš›ä¸Š ROOT_DIR / USER_DATA_DIR è·Ÿå‰é¢ä¸€è‡´ï¼‰
# =========================
APP_DIR = Path(__file__).resolve().parent
ROOT_DIR = APP_DIR.parent
USER_DATA_DIR = ROOT_DIR / "user_data"
USER_DATA_DIR.mkdir(exist_ok=True)
JOB_PROFILES_PATH = USER_DATA_DIR / "job_profiles.json"

# éŒ„éŸ³ï¼éŒ„å½±æœƒå­˜åˆ°é€™è£¡ï¼šuser_data/session_media/<profile_id>/xxx.webm
SESSION_MEDIA_DIR = USER_DATA_DIR / "session_media"
SESSION_MEDIA_DIR.mkdir(parents=True, exist_ok=True)

sys.path.append(str(ROOT_DIR))

app = FastAPI(title="Intelliview Coach")

# static æª”æ¡ˆï¼ˆCSS, JSï¼‰
static_dir = APP_DIR / "static"
static_dir.mkdir(parents=True, exist_ok=True)
app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

# ğŸ”¥ æ–°å¢ï¼šmedia æª”æ¡ˆï¼ˆaudio/videoï¼‰
app.mount("/media", StaticFiles(directory=str(SESSION_MEDIA_DIR)), name="media")

templates = Jinja2Templates(directory=str(APP_DIR / "templates"))


def ensure_project_dirs(project_id: str):
    raw_dir = USER_DATA_DIR / "raw" / project_id
    parsed_dir = USER_DATA_DIR / "parsed" / project_id
    raw_dir.mkdir(parents=True, exist_ok=True)
    parsed_dir.mkdir(parents=True, exist_ok=True)
    return raw_dir, parsed_dir

class JobProfileCreate(BaseModel):
    profile_id: str
    job_title: str
    company: str | None = None
    jd_text: str
    resume_id: str

# =========================
# FrontEnd Page
# =========================
# é¦–é ï¼šLanding page
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse("home.html", {"request": request})

# å±¥æ­·è¨­å®šé ï¼šåŸæœ¬çš„ editor æ¬åˆ°é€™è£¡
@app.get("/resume", response_class=HTMLResponse, name="resume_page")
async def resume_page(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/profiles", response_class=HTMLResponse, name="profiles_page")
async def profiles_page(request: Request):
    profiles = load_job_profiles()
    # ç°¡å–®æŒ‰ç…§ updated_at æ’åºï¼ˆæ–°åˆ°èˆŠï¼‰
    profiles_sorted = sorted(
        profiles,
        key=lambda p: p.get("updated_at", ""),
        reverse=True,
    )

    # ç‚ºæ¯å€‹ profile ç®—ä¸€æ¬¡ stats æ‘˜è¦
    enriched = []
    for p in profiles_sorted:
        pid = p.get("profile_id")
        stats = get_practice_stats(pid)
        enriched.append(
            {
                **p,
                "stats": stats,
            }
        )

    return templates.TemplateResponse(
        "profiles.html",
        {
            "request": request,
            "profiles": enriched,   # â­ ç”¨ enrichedï¼Œè€Œä¸æ˜¯ profiles_sorted
        },
    )

@app.get("/profiles/new", response_class=HTMLResponse, name="new_profile_page")
async def new_profile_page(
    request: Request,
    resume_id: str | None = None,
):
    # æƒæå·²æœ‰çš„ resume ç‰ˆæœ¬ï¼ˆparsed åº•ä¸‹çš„è³‡æ–™å¤¾åï¼‰
    parsed_root = USER_DATA_DIR / "parsed"
    resume_ids: list[str] = []
    if parsed_root.exists():
        for folder in parsed_root.iterdir():
            if folder.is_dir():
                resume_ids.append(folder.name)
    resume_ids.sort()

    return templates.TemplateResponse(
        "new_profile.html",
        {
            "request": request,
            "resume_ids": resume_ids,
            "default_resume_id": resume_id,
        },
    )


@app.get("/api/profile/{profile_id}")
async def api_get_profile(profile_id: str):
    profiles = load_job_profiles()
    p = next((x for x in profiles if x.get("profile_id") == profile_id), None)
    if not p:
        raise HTTPException(status_code=404, detail="Profile not found")
    return {
        "profile_id": p.get("profile_id"),
        "job_title": p.get("job_title"),
        "company": p.get("company"),
        "resume_id": p.get("resume_id"),
        "jd_text": p.get("jd_text", ""),
    }

def load_all_profiles():
    with open("user_data/job_profiles.json", "r") as f:
        data = json.load(f)
    # åªæ‹¿å…§å±¤çš„ list
    return data.get("profiles", [])

@app.get("/profiles/{profile_id}/history", response_class=HTMLResponse)
async def practice_history_page(request: Request, profile_id: str):
    stats = get_practice_stats(profile_id)
    session = load_session(profile_id)
    turns = session.get("turns", [])

    all_profiles = load_all_profiles()  # â­ æ–°å¢é€™è¡Œ

    return templates.TemplateResponse(
        "history.html",
        {
            "request": request,
            "profile_id": profile_id,
            "stats": stats,
            "turns": turns,
            "all_profiles": all_profiles,   # â­ å‚³çµ¦ template
        },
    )


@app.get("/practice/{profile_id}", response_class=HTMLResponse, name="practice_page")
async def practice_page(request: Request, profile_id: str):
    return templates.TemplateResponse(
        "practice.html",
        {"request": request, "profile_id": profile_id},
    )

@app.get("/api/profile_entries/{profile_id}")
async def api_profile_entries(profile_id: str):
    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    resume_id = profile.get("resume_id")
    if not resume_id:
        raise HTTPException(status_code=400, detail="Profile has no resume_id")

    entries, _ = load_resume_entries_and_embs(resume_id)

    seen = set()
    items = []
    for e in entries:
        section = e.get("section") or "EXPERIENCE"
        entry = e.get("entry") or ""
        if not entry:
            continue
        key = f"{section}||{entry}"
        if key in seen:
            continue
        seen.add(key)
        label = f"[{section}] {entry}"
        items.append({"entry_key": key, "label": label})

    return {"entries": items}

@app.get("/api/practice_stats/{profile_id}")
async def api_practice_stats(profile_id: str):
    stats = get_practice_stats(profile_id)
    return stats

@app.get("/api/practice_history/{profile_id}")
async def api_practice_history(profile_id: str):
    session = load_session(profile_id)
    turns = session.get("turns", [])
    # ä½ ä¹Ÿå¯ä»¥åœ¨é€™è£¡åšç°¡å–®æ’åºæˆ–æˆªæ–·
    return {"turns": turns}

@app.get("/mock_settings", response_class=HTMLResponse, name="mock_settings_page")
async def mock_settings_page(
    request: Request,
    resume_id: str | None = None,
):
    # æƒæ parsed/ åº•ä¸‹æ‰€æœ‰ resume version
    parsed_root = USER_DATA_DIR / "parsed"
    resume_ids: list[str] = []
    if parsed_root.exists():
        for folder in parsed_root.iterdir():
            if folder.is_dir():
                resume_ids.append(folder.name)
    resume_ids.sort()

    all_profiles = load_job_profiles()  # è®“ dropdown æœ‰ profile åˆ—è¡¨

    return templates.TemplateResponse(
        "mock_settings.html",
        {
            "request": request,
            "resume_ids": resume_ids,
            "default_resume_id": resume_id,
            "all_profiles": all_profiles,
        },
    )

@app.get("/mock_interview")
async def mock_interview_page(request: Request):
    q = request.query_params

    profile_id = q.get("profile_id")
    if not profile_id:
        raise HTTPException(status_code=400, detail="profile_id is required")

    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    resume_id = profile.get("resume_id")
    if not resume_id:
        raise HTTPException(
            status_code=400,
            detail="This profile has no linked resume. Please set it in Profiles first.",
        )

    mode = q.get("mode", "realistic")
    length_type = q.get("length_type", "questions")
    hint_level = q.get("hint_level", "standard")

    num_questions = q.get("num_questions")
    time_limit = q.get("time_limit")

    num_questions_int = int(num_questions) if num_questions else None
    time_limit_int = int(time_limit) if time_limit else None

    # ====== é€™æ˜¯å¾ settings.html ä¾†çš„ interviewer è¨­å®š ======
    interviewer_gender = q.get("interviewer_gender", "auto")

    role_preset = q.get("interviewer_role") or "senior_engineer"
    role_custom = q.get("interviewer_role_custom") or ""

    style_preset = q.get("interviewer_style_preset") or "balanced"
    style_custom = q.get("interviewer_style_custom") or ""

    extra_notes = (q.get("interviewer_extra_notes") or "").strip()

    # å¯ä»¥ç°¡å–® resolveï¼ˆä½ å¦‚æœæœ‰è‡ªå·±çš„ resolver ä¹Ÿå¯ä»¥ç”¨è‡ªå·±çš„ï¼‰
    def resolve_role(preset: str, custom: str) -> str:
        if preset == "custom":
            return custom or "an interviewer for this role"
        # å¯ä»¥è‡ªå·± mapï¼›é€™è£¡å…ˆç°¡å–®å¯«
        mapping = {
            "senior_engineer": "a senior data / ML / SWE engineer on the team youâ€™d work with",
            "hiring_manager": "the hiring manager who cares about team fit, ownership, and impact",
            "recruiter": "a recruiter or HR partner focusing on overall fit and communication",
            "peer_teammate": "a future teammate who wants to know what itâ€™s like to work with you day to day",
            "executive": "a director or VP who cares about business impact and prioritization",
        }
        return mapping.get(preset, "an interviewer for this role")

    def resolve_style(preset: str, custom: str) -> str:
        if preset == "custom":
            return custom or "balanced, realistic, and professional"
        mapping = {
            "balanced": "balanced, neutral but probing",
            "supportive": "supportive, encouraging and patient",
            "direct": "direct and concise, to the point",
            "challenging": "challenging and skeptical, pushes on vague claims",
            "high_pressure": "fast-paced, high-pressure, tests how the candidate handles stress",
        }
        return mapping.get(preset, "balanced, realistic, and professional")

    resolved_role = resolve_role(role_preset, role_custom)
    resolved_style = resolve_style(style_preset, style_custom)

    # â­ é€™å€‹ persona string æœƒä¸Ÿåˆ° TTS çš„ req.instructions
    tts_persona = (
        f"{resolved_role}. {resolved_style}. "
        f"{extra_notes}" if extra_notes else f"{resolved_role}. {resolved_style}."
    )

    # çµ„æˆ interviewer_profile ä¸Ÿé€² session
    interviewer_profile = {
        "gender": interviewer_gender,
        "role_preset": role_preset,
        "role_resolved": resolved_role,
        "style_preset": style_preset,
        "style_resolved": resolved_style,
        "extra_notes": extra_notes,
        # é€™å€‹æ¬„ä½æœƒæœ€å¾Œè®Šæˆ TTS çš„ instructions â†’ persona_to_instructions()
        "tts_persona": tts_persona,
    }

    # ====== å»ºç«‹ sessionï¼šé€™è£¡è¦è¨˜å¾—å‚³ interviewer_profile=... ======
    session = mock_interview.create_mock_session(
        profile_id=profile_id,
        resume_id=resume_id,
        mode=mode,
        length_type=length_type,
        hint_level=hint_level,
        num_questions=num_questions_int,
        time_limit=time_limit_int,
        interviewer_profile=interviewer_profile,   # ğŸ‘ˆ é—œéµ
    )

    # å‰ç«¯è¦ç”¨ `SESSION_CONFIG` ä¾† call /api/tts_question
    session_config = {
        "session_id": session["session_id"],
        "profile_id": profile_id,
        "resume_id": resume_id,
        "mode": mode,
        "length_type": length_type,
        "hint_level": hint_level,
        "num_questions": session.get("num_questions"),
        "time_limit": session.get("time_limit"),

        # è®“ JS å¯ä»¥æ‹¿ä¾†ç•¶ voice / instructions
        "interviewer_gender": interviewer_gender,
        "interviewer_role": resolved_role,
        "interviewer_style": resolved_style,
        "interviewer_extra_notes": extra_notes,
        "tts_instructions": tts_persona,
    }

    import json as _json
    session_config_json = _json.dumps(session_config)

    return templates.TemplateResponse(
        "mock_interview.html",
        {
            "request": request,
            "session_config_json": session_config_json,
        },
    )




@app.get("/profiles/{profile_id}/mock_history")
async def mock_history_index(request: Request, profile_id: str):
    sessions = mock_interview.list_mock_sessions_for_profile(profile_id)
    all_profiles = load_all_profiles()  # è·Ÿ practice history ä¸€æ¨£ï¼Œå³ä¸Šç”¨ä¾†åˆ‡ profile

    return templates.TemplateResponse(
        "mock_history.html",
        {
            "request": request,
            "profile_id": profile_id,
            "sessions": sessions,
            "all_profiles": all_profiles,
        },
    )


# ================================
#  Single mock result page
# ================================
@app.get("/mock/{session_id}")
def mock_report_page(request: Request, session_id: str):
    """
    é¡¯ç¤ºå–®ä¸€ mock interview çš„å ±å‘Šé 
    """
    report = mock_interview.load_mock_result(session_id)
    return templates.TemplateResponse(
        "mock_report.html",
        {
            "request": request,
            "report": report,
        }
    )


@app.get("/profiles/{profile_id}/mock_history/{session_id}")
async def mock_report_page_profile(request: Request, profile_id: str, session_id: str):
    report = mock_interview.load_mock_result(session_id)
    return templates.TemplateResponse(
        "mock_report.html",
        {"request": request, "profile_id": profile_id, "report": report},
    )

# =========================
# APIï¼šä¸Šå‚³å±¥æ­·ä¸¦ parse
# =========================
@app.post("/api/upload_resume")
async def upload_resume(
    project_id: str = Form(...),
    file: UploadFile = File(...)
):
    # æº–å‚™ç›®éŒ„
    raw_dir = USER_DATA_DIR / "raw" / project_id
    parsed_dir = USER_DATA_DIR / "parsed" / project_id
    raw_dir.mkdir(parents=True, exist_ok=True)
    parsed_dir.mkdir(parents=True, exist_ok=True)

    # æ°¸é å­˜æˆ resume.pdf
    resume_path = raw_dir / "resume.pdf"
    content = await file.read()
    with open(resume_path, "wb") as f:
        f.write(content)

    # ç”¨ä½ è‡ªå·±çš„ parser
    raw_text = extract_pdf_text(str(resume_path))
    entries = parse_resume_entries(raw_text)
    metadata = extract_metadata_sections(raw_text)
    education_structured = extract_structured_education(raw_text)

    # å­˜åŸå§‹ parse çµæœï¼ˆä¹‹å¾Œ Save æ‰æœƒå­˜ edited ç‰ˆï¼‰
    with open(parsed_dir / "experience_entries.json", "w", encoding="utf-8") as f:
        json.dump(entries, f, ensure_ascii=False, indent=2)
    with open(parsed_dir / "metadata.json", "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    with open(parsed_dir / "education_structured.json", "w", encoding="utf-8") as f:
        json.dump(education_structured, f, ensure_ascii=False, indent=2)

    return JSONResponse(
        content={
            "project_id": project_id,
            "entries": entries,
            "metadata": metadata,
            "education_structured": education_structured
        }
    )


# =========================
# APIï¼šå­˜ç·¨è¼¯å¾Œçš„çµæœ
# =========================
class SaveResumePayload(BaseModel):
    project_id: str
    entries: list[dict]
    metadata: dict
    education_structured: list[dict]


@app.post("/api/save_resume")
async def save_resume(payload: SaveResumePayload):
    project_id = payload.project_id
    parsed_dir = USER_DATA_DIR / "parsed" / project_id
    parsed_dir.mkdir(parents=True, exist_ok=True)

    # 1) å­˜ edited ç‰ˆæœ¬
    with open(parsed_dir / "experience_entries_edited.json", "w", encoding="utf-8") as f:
        json.dump(payload.entries, f, ensure_ascii=False, indent=2)

    with open(parsed_dir / "metadata.json", "w", encoding="utf-8") as f:
        json.dump(payload.metadata, f, ensure_ascii=False, indent=2)

    with open(parsed_dir / "education_structured.json", "w", encoding="utf-8") as f:
        json.dump(payload.education_structured, f, ensure_ascii=False, indent=2)

    # 2) ç”¨ fine-tuned model å»º embeddings
    #    â†’ user_data/embeddings/{project_id}/resume_bullets.npy
    try:
        build_resume_embeddings(project_id)
        built = True
    except Exception as e:
        # ä¸è¦è®“æ•´å€‹ API çˆ†æ‰ï¼Œreturn è®“å‰ç«¯çŸ¥é“ embedding å¤±æ•—
        print("Error building embeddings:", e)
        built = False

    # 3) å›å‚³çµ¦å‰ç«¯
    return JSONResponse(
        content={
            "status": "ok",
            "project_id": project_id,
            "embeddings_built": built
        }
    )

@app.post("/api/create_job_profile")
async def create_job_profile(payload: JobProfileCreate):
    profiles = load_job_profiles()

    now = datetime.utcnow().isoformat() + "Z"

    # å¦‚æœåŒä¸€å€‹ profile_id å·²å­˜åœ¨ï¼Œå°±æ›´æ–°
    existing = None
    for p in profiles:
        if p.get("profile_id") == payload.profile_id:
            existing = p
            break

    if existing:
        existing.update(
            {
                "job_title": payload.job_title,
                "company": payload.company,
                "jd_text": payload.jd_text,
                "resume_id": payload.resume_id,
                "updated_at": now,
            }
        )
    else:
        profiles.append(
            {
                "profile_id": payload.profile_id,
                "job_title": payload.job_title,
                "company": payload.company,
                "jd_text": payload.jd_text,
                "resume_id": payload.resume_id,
                "created_at": now,
                "updated_at": now,
            }
        )

    save_job_profiles(profiles)
    return JSONResponse(
        content={"status": "ok", "profile_id": payload.profile_id},
    )

class NextQuestionRequest(BaseModel):
    profile_id: str
    mode: str                    # "auto" | "behavioral" | "project" | "technical" | "case" | "custom"
    behavioral_type: Optional[str] = None
    entry_key: Optional[str] = None
    prev_answer: Optional[str] = None
    custom_question: Optional[str] = None

@app.post("/api/next_question")
async def api_next_question(req: NextQuestionRequest):
    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == req.profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    jd_text = profile.get("jd_text", "")
    mode = (req.mode or "auto").lower()

    # === auto: LLM + JD + é¿å…é‡è¤‡ ===
    if mode == "auto":
        asked = get_asked_questions(req.profile_id, mode="auto")
        question = call_llm_for_question(jd_text, mode="auto", avoid=asked)

        bullets = retrieve_bullets_for_profile(req.profile_id, question, top_k=5)
        tag = "Auto (from JD)"
        behavioral_type = None
        entry_key = None

    # === behavioral: é¡Œåº« + subtype + é¿å…é‡è¤‡ ===
    elif mode == "behavioral":
        subtype = req.behavioral_type or "random"
        question = get_behavioral_question(req.profile_id, subtype)
        bullets = retrieve_bullets_for_profile(req.profile_id, question, top_k=5)
        tag = f"Behavioral Â· {subtype}"
        behavioral_type = subtype
        entry_key = None

    # === project deep dive ===
    elif mode == "project":
        if not req.entry_key:
            raise HTTPException(status_code=400, detail="entry_key required for project mode")

        entry_key = req.entry_key
        resume_id = profile.get("resume_id")
        if not resume_id:
            raise HTTPException(status_code=400, detail="Profile has no resume_id")

        entry_bullets = get_bullets_for_entry(resume_id, entry_key)

        # å»º previous_qasï¼ˆsession å…§æ‰€æœ‰é€™å€‹ entry çš„ Q/Aï¼‰
        session = load_session(req.profile_id)
        qa_history = []
        for t in session.get("turns", []):
            if t.get("mode") == "project" and t.get("entry_key") == entry_key:
                qa_history.append(
                    {
                        "question": t.get("question"),
                        "answer": t.get("user_answer") or "",
                    }
                )

        # æŠŠé€™ä¸€è¼ªä½¿ç”¨è€…å‰›æ‰“çš„ç­”æ¡ˆï¼ˆprev_answerï¼‰ä¹Ÿä¸²é€² context
        last_question = qa_history[-1]["question"] if qa_history else None
        if req.prev_answer and last_question:
            qa_history.append({"question": last_question, "answer": req.prev_answer})

        question = call_llm_for_project_question(
            jd_text=jd_text,
            entry_title=entry_key.split("||", 1)[1],
            bullets=entry_bullets,
            previous_qas=qa_history,
        )
        bullets = entry_bullets
        tag = "Project deep dive"
        behavioral_type = None

    # === technical: ç”¨ JD ç”ŸæŠ€è¡“é¡Œ ===
    elif mode == "technical":
        asked = get_asked_questions(req.profile_id, mode="technical")
        question = call_llm_for_question(
            jd_text=jd_text,
            mode="technical",
            avoid=asked,
        )
        bullets = retrieve_bullets_for_profile(req.profile_id, question, top_k=5)
        tag = "Technical question"
        behavioral_type = None
        entry_key = None

    # === case: ç”¨ JD ç”Ÿ case reasoning é¡Œ ===
    elif mode == "case":
        asked = get_asked_questions(req.profile_id, mode="case")
        question = call_llm_for_question(
            jd_text=jd_text,
            mode="case",
            avoid=asked,
        )
        bullets = retrieve_bullets_for_profile(req.profile_id, question, top_k=5)
        tag = "Case interview question"
        behavioral_type = None
        entry_key = None

    # === custom: å‰ç«¯è‡ªè¨‚é¡Œç›® ===
    elif mode == "custom":
        if not req.custom_question:
            raise HTTPException(status_code=400, detail="custom_question is required for custom mode")

        question = req.custom_question
        bullets = retrieve_bullets_for_profile(req.profile_id, question, top_k=5)
        tag = "Custom question"
        behavioral_type = None
        entry_key = None

    else:
        raise HTTPException(status_code=400, detail=f"Unsupported mode: {mode}")

    return {
        "question": question,
        "tag": tag,
        "bullets": bullets,
        "mode": mode,
        "behavioral_type": behavioral_type,
        "entry_key": entry_key,
    }

class BulletsRequest(BaseModel):
    profile_id: str
    question: str

@app.post("/api/retrieve_bullets")
async def api_retrieve_bullets(req: BulletsRequest):
    bullets = retrieve_bullets_for_profile(req.profile_id, req.question, top_k=3)
    return {"bullets": bullets}

class CoachChatRequest(BaseModel):
    profile_id: str
    mode: str
    question: str
    user_message: str
    sample_answer: Optional[str] = None
    bullets: Optional[List[Dict[str, Any]]] = None
    history: Optional[List[Dict[str, str]]] = None   # [{role, content}, ...]

@app.post("/api/coach_chat")
async def api_coach_chat(req: CoachChatRequest):
    """
    Coach chat:
    - ä¸€å®šæœƒæœ‰ç•¶å‰ question
    - sample_answer å¯ä»¥ç‚ºç©ºï¼ˆä»£è¡¨é‚„æ²’ generateï¼‰
    - bullets å¦‚æœæ²’å‚³ï¼Œå°±è‡ªå·± RAG æ’ˆ top-k
    - history ç”¨ä¾†ä¿ç•™æ­¤è¼ª coach å°è©±è¨˜æ†¶
    """
    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == req.profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    jd_text = profile.get("jd_text", "")

    # è‹¥å‰ç«¯æ²’å‚³ bulletsï¼Œè‡ªå·± RAG ä¸€ä»½
    if req.bullets:
        bullets = req.bullets
    else:
        bullets = retrieve_bullets_for_profile(req.profile_id, req.question, top_k=5)

    # æº–å‚™ bullet context
    bullet_lines = []
    for b in bullets:
        entry = b.get("entry") or "Unknown entry"
        text = b.get("text") or ""
        bullet_lines.append(f"- [{entry}] {text}")
    bullet_block = "\n".join(bullet_lines) if bullet_lines else "(none)"

    # å°è©±æ­·å²ï¼ˆåªæ‹¿æœ€å¾Œå¹¾è¼ªï¼‰
    history = req.history or []
    trimmed_history = history[-8:]  # æœ€å¤š 8 å‰‡

    # system + user prompt
    system_msg = (
        "You are an interview coach helping a candidate refine their answer, do not give user the sample answer unless they ask for it. "
        "Use the job description, question, resume bullets, and (if available) "
        "the current sample answer. Be concrete and actionable."
    )

    context_block = f"""
Job description:
{jd_text}

Current interview question:
{req.question}

Relevant resume bullets:
{bullet_block}

Current sample answer (may be empty if not generated yet):
{req.sample_answer or "(none yet â€” help them think about how to answer first.)"}
"""

    messages = [{"role": "system", "content": system_msg}]
    messages.append({"role": "user", "content": context_block})

    # åŠ å…¥æ­·å²
    for m in trimmed_history:
        role = m.get("role", "user")
        content = m.get("content", "")
        if not content:
            continue
        messages.append({"role": role, "content": content})

    # æœ€å¾Œé€™ä¸€è¼ªä½¿ç”¨è€…çš„è¨Šæ¯
    messages.append({"role": "user", "content": req.user_message})

    from core.rag_pipeline import client as rag_client  # é¿å…åç¨±è¡çª

    resp = rag_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.6,
    )
    reply = resp.choices[0].message.content.strip()

    return {
        "reply": reply,
        "bullets": bullets,  # è®“å‰ç«¯è‹¥è¦çš„è©±å¯ä»¥æ›´æ–° sidebar
    }


class SampleAnswerRequest(BaseModel):
    profile_id: str
    question: str
    mode: str
    behavioral_type: Optional[str] = None
    entry_key: Optional[str] = None
    user_answer: Optional[str] = None
    bullets: Optional[List[Dict[str, Any]]] = None

@app.post("/api/generate_sample_answer")
async def api_generate_sample_answer(req: SampleAnswerRequest):
    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == req.profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    jd_text = profile.get("jd_text", "")

    # è‹¥å‰ç«¯æ²’å‚³ bulletsï¼Œå°±è®“å¾Œç«¯è‡ªå·± RAG æ‰¾
    if req.bullets:
        bullets = req.bullets
    else:
        bullets = retrieve_bullets_for_profile(req.profile_id, req.question, top_k=5)

    llm_result = call_llm_for_sample_answer(
        question=req.question,
        jd_text=jd_text,
        bullets=bullets,
        user_answer=req.user_answer,
    )

    return {
        "answer": llm_result.get("answer", ""),
        "hint": llm_result.get("hint", ""),
        "rationale": llm_result.get("rationale", ""),
        "bullets": bullets,
    }


class SaveUserAnswerRequest(BaseModel):
    profile_id: str
    question: str
    mode: str
    behavioral_type: Optional[str] = None
    entry_key: Optional[str] = None
    user_answer: Optional[str] = None
    bullets: Optional[List[Dict[str, Any]]] = None
    sample_answer: Optional[str] = None
    thread_id: Optional[str] = None     
    is_followup: bool = False  

@app.post("/api/save_user_answer")
async def api_save_user_answer(req: SaveUserAnswerRequest):
    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == req.profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    jd_text = profile.get("jd_text", "")

    if not req.user_answer or not req.user_answer.strip():
        raise HTTPException(status_code=400, detail="user_answer is empty")

    # bullets: å‰ç«¯æœ‰å‹¾é¸å°±ç”¨å®ƒï¼›æ²’æœ‰å°±è‡ªå·± RAG
    if req.bullets:
        bullets = req.bullets
    else:
        bullets = retrieve_bullets_for_profile(req.profile_id, req.question, top_k=5)

    # è©•åˆ†
    eval_result = evaluate_answer(
        question=req.question,
        jd_text=jd_text,
        bullets=bullets,
        user_answer=req.user_answer,
    )

    # ---- å…¼å®¹èˆŠæ¬„ä½çš„ mapping ----
    # æ–°ç‰ˆ evaluate_answer ç”¨ overall_score / improvements_overview
    score = eval_result.get("overall_score")
    if score is None:
        score = eval_result.get("score", 5)

    strengths = (eval_result.get("strengths") or "").strip()

    improvements = (
        eval_result.get("improvements_overview")
        or eval_result.get("improvements")
        or ""
    ).strip()

    # å¯«å…¥ sessionï¼Œåªåœ¨é€™ä¸€æ­¥æ‰ log
    log_practice_turn(
        profile_id=req.profile_id,
        question=req.question,
        sample_answer=req.sample_answer,
        bullets=bullets,
        mode=req.mode,
        behavioral_type=req.behavioral_type,
        entry_key=req.entry_key,
        user_answer=req.user_answer,
        score=score,
        strengths=strengths,
        improvements=improvements,
        thread_id=req.thread_id,
        is_followup=req.is_followup,
    )

    # å›çµ¦å‰ç«¯çš„ eval_result ä¿ç•™å®Œæ•´æ–°ç‰ˆçµæ§‹
    #ï¼ˆå¦‚æœå‰ç«¯æœ‰å¯«æ­»ç”¨ score / improvementsï¼Œä¹Ÿå¯ä»¥é †æ‰‹è£œä¸Šï¼‰
    eval_result_out = dict(eval_result)
    eval_result_out.setdefault("score", score)
    eval_result_out.setdefault("improvements", improvements)

    return eval_result_out

class FollowupQuestionRequest(BaseModel):
    profile_id: str
    mode: str                     # "auto" | "behavioral" | "project" | "custom"
    base_question: str            # ä¸»é¡Œç›®çš„å•é¡Œï¼ˆç¬¬ä¸€é¡Œï¼‰
    user_answer: Optional[str] = None  # å‰›å‰›é€™é¡Œçš„æœ€æ–°å›ç­”ï¼ˆå°šæœªå­˜æª”ä¹Ÿå¯ä»¥ï¼‰
    thread_id: Optional[str] = None    # å¦‚æœå‰ç«¯æœ‰ thread_idï¼ˆUUIDï¼‰ï¼Œå°±å‚³ï¼›æ²’æœ‰å°±ç”¨ base_question ç•¶é è¨­
    entry_key: Optional[str] = None
    bullets: Optional[List[Dict[str, Any]]] = None

MAX_FOLLOWUPS_PER_THREAD = 3  # ä½ å¯ä»¥ä¹‹å¾Œèª¿æ•´é€™å€‹æ•¸å­—

@app.post("/api/followup_question")
async def api_followup_question(req: FollowupQuestionRequest):
    """
    ç”¢ç”Ÿè¿½å•å•é¡Œï¼š
    - é©ç”¨æ‰€æœ‰ modeï¼ˆauto/behavioral/project/customï¼‰
    - æ ¹æ“š base_question + è©² thread çš„ QA æ­·å² + æœ€æ–° user_answer ä¾†å•
    - åŒä¸€å€‹ thread å…§é¿å…å•é‡è¤‡çš„å•é¡Œ
    """
    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == req.profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    jd_text = profile.get("jd_text", "")
    mode = (req.mode or "auto").lower()

    # 1) bulletsï¼šæ²’çµ¦å°±è‡ªå·± RAG
    if req.bullets:
        bullets = req.bullets
    else:
        bullets = retrieve_bullets_for_profile(req.profile_id, req.base_question, top_k=5)

    # 2) æ‰¾å‡ºé€™å€‹ thread åº•ä¸‹çš„æ—¢æœ‰ QAï¼ˆå·²å­˜é€² turns çš„ï¼‰
    session = load_session(req.profile_id)
    thread_id = req.thread_id or req.base_question  # ç°¡å–®ç‰ˆï¼šæ²’ thread_id å°±ç”¨ä¸»é¡Œç›®ç•¶ ID

    thread_turns = [
        t for t in session.get("turns", [])
        if t.get("thread_id") == thread_id
    ]

    # è¨ˆç®—å·²ç¶“è¿½å•å¹¾é¡Œ
    followup_count = sum(1 for t in thread_turns if t.get("is_followup"))
    if followup_count >= MAX_FOLLOWUPS_PER_THREAD:
        return {
            "question": None,
            "done": True,
            "message": "This topic has already been explored with several follow-up questions. Consider moving on to a new question.",
            "thread_id": thread_id,
        }

    # 3) çµ„ QA historyï¼ˆåªçµ¦ LLM çœ‹ï¼Œä¸ä¸€å®šå…¨éƒ¨è¦é¡¯ç¤ºåœ¨ UIï¼‰
    qa_history = []
    for t in thread_turns:
        q = t.get("question") or ""
        a = t.get("user_answer") or ""
        if q or a:
            qa_history.append({"question": q, "answer": a})

    # æŠŠé€™ä¸€è¼ªå‰›è¼¸å…¥çš„ user_answer ä¹ŸåŠ é€²å»ï¼ˆå³ä½¿é‚„æ²’å­˜æª”ï¼‰
    if req.user_answer:
        qa_history.append({"question": req.base_question, "answer": req.user_answer})

    # 4) thread å…§é¿å…é‡è¤‡çš„å•é¡Œï¼ˆä¸»é¡Œ + æ—¢æœ‰è¿½å•ï¼‰
    avoid = set()
    for t in thread_turns:
        q = t.get("question")
        if q:
            avoid.add(q.strip())
    avoid.add(req.base_question.strip())

    # 5) å¯¦éš›å« LLM ç”Ÿè¿½å•å•é¡Œï¼ˆå«é¿å…é‡è¤‡ï¼‰
    followup_q = generate_followup_question(
        jd_text=jd_text,
        mode=mode,
        base_question=req.base_question,
        bullets=bullets,
        qa_history=qa_history,
        avoid=avoid,
    )

    if not followup_q:
        # ä»£è¡¨ LLM æ€éº¼æ¨£éƒ½ç”Ÿä¸å‡ºè¶³å¤ ä¸åŒçš„æ–°å•é¡Œ
        return {
            "question": None,
            "done": True,
            "message": "The model could not generate a sufficiently different follow-up question. Let's move on to a new topic.",
            "thread_id": thread_id,
        }

    return {
        "question": followup_q,
        "mode": mode,
        "bullets": bullets,
        "entry_key": req.entry_key,
        "thread_id": thread_id,
        "is_followup": True,
        "done": False,
        "tag": f"Follow-up \u00b7 {mode}",
    }

@app.post("/api/save_user_answer_with_media")
async def api_save_user_answer_with_media(
    meta: str = Form(...),
    media: UploadFile | None = File(None),
):
    """
    å‰ç«¯æœƒç”¨ FormData å‚³ï¼š
      - meta: JSON å­—ä¸²ï¼Œå…§å®¹è·Ÿ SaveUserAnswerRequest ä¸€æ¨£ï¼ˆæ²’æœ‰ user_answer ä¹Ÿå¯ä»¥ï¼‰
      - media: éŒ„éŸ³/éŒ„å½±æª” (optional)

    æµç¨‹ï¼š
      1. å…ˆæŠŠ media å­˜åˆ° user_data/session_media/<profile_id>/xxx.webm
      2. å¦‚æœ meta è£¡æ²’æœ‰ user_answer ä¸”æœ‰ media â†’ ç”¨ Whisper-1 è½‰éŒ„æˆæ–‡å­—
      3. æŠŠè½‰éŒ„æ–‡å­—å¡«é€² req.user_answer â†’ èµ°åŸæœ¬è©•åˆ† & log pipeline
      4. å›å‚³è©•åˆ†çµæœï¼ˆå¦å¤–å¤šå¸¶ transcriptï¼Œå‰ç«¯ä¹‹å¾Œå¯ä»¥ç”¨ä¾†é¡¯ç¤ºï¼‰
    """
    # ----- è§£æ meta -----
    try:
        meta_dict = json.loads(meta)
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid meta JSON")

    # ç”¨æ—¢æœ‰çš„ Pydantic model åšé©—è­‰
    req = SaveUserAnswerRequest(**meta_dict)

    profiles = load_job_profiles()
    profile = next((p for p in profiles if p.get("profile_id") == req.profile_id), None)
    if profile is None:
        raise HTTPException(status_code=404, detail="Profile not found")

    jd_text = profile.get("jd_text", "")

    # ----- åˆ¤æ–·æ˜¯å¦æœ‰æ–‡å­— / media -----
    has_text = bool(req.user_answer and req.user_answer.strip())
    has_media_upload = media is not None

    # å¦‚æœå…©å€‹éƒ½æ²’æœ‰ï¼Œç›´æ¥æ“‹æ‰
    if not has_text and not has_media_upload:
        raise HTTPException(status_code=400, detail="No text answer or media provided")

    # ---------- è™•ç† media æª”æ¡ˆï¼šå­˜åˆ° SESSION_MEDIA_DIR ----------
    media_type: Optional[str] = None
    media_filename: Optional[str] = None
    media_duration_ms: Optional[int] = None
    saved_media_path: Optional[Path] = None

    # meta è£¡å¯ä»¥å¸¶ä¸€å€‹ media_meta: {type, durationMs}
    media_meta = meta_dict.get("media_meta") or {}
    if media_meta:
        media_type = media_meta.get("type")
        media_duration_ms = media_meta.get("durationMs")

    if has_media_upload:
        content_type = media.content_type or ""
        if "video" in content_type:
            ext = ".webm"  # video/webm
        elif "audio" in content_type:
            ext = ".webm"  # audio/webm
        else:
            ext = ".bin"

        ts = datetime.utcnow().isoformat().replace(":", "-")
        safe_profile = req.profile_id.replace("/", "_")
        filename = f"{safe_profile}_{ts}{ext}"

        profile_dir = SESSION_MEDIA_DIR / safe_profile
        profile_dir.mkdir(parents=True, exist_ok=True)

        media_path = profile_dir / filename
        content = await media.read()
        media_path.write_bytes(content)

        # å­˜åœ¨ session.json è£¡é¢çš„è·¯å¾‘ï¼šç›¸å°æ–¼ SESSION_MEDIA_DIR
        media_filename = str(media_path.relative_to(SESSION_MEDIA_DIR))
        saved_media_path = media_path

        # å¦‚æœå‰ç«¯æ²’å‚³ media_typeï¼Œå°±å¾ content_type çŒœ
        if media_type is None:
            if "video" in content_type:
                media_type = "video"
            elif "audio" in content_type:
                media_type = "audio"

    # ---------- å¦‚æœæ²’æœ‰æ–‡å­—ä½†æœ‰ media â†’ åšè½‰éŒ„ ----------
    transcript_text: Optional[str] = None

    if (not has_text) and saved_media_path is not None:
        try:
            # ä½ ä¹‹å¾Œå¯ä»¥ä¾ç…§ profile / user ç¿’æ…£èª¿æ•´ language
            transcript_text = transcribe_media(
                saved_media_path,
                language="en",
                prompt="This is an interview answer from a candidate. Please transcribe clearly.",
            )
        except Exception as e:
            print(f"[api_save_user_answer_with_media] Transcription error: {e}")
            transcript_text = None

        if transcript_text and transcript_text.strip():
            req.user_answer = transcript_text.strip()
            has_text = True  # ä¹‹å¾Œå¯ä»¥é€²å…¥åŸæœ¬çš„è©•åˆ†æµç¨‹

    # ---------- bulletsï¼šè·ŸåŸæœ¬ä¸€æ¨£ ----------
    if req.bullets:
        bullets = req.bullets
    else:
        bullets = retrieve_bullets_for_profile(req.profile_id, req.question, top_k=5)

    # ---------- è©•åˆ†é‚è¼¯ï¼šåªè¦æœ€å¾Œæœ‰æ–‡å­—å°±è©•åˆ† ----------
    if has_text:
        eval_result = evaluate_answer(
            question=req.question,
            jd_text=jd_text,
            bullets=bullets,
            user_answer=req.user_answer,
        )
        score = eval_result["score"]
        strengths = eval_result["strengths"]
        improvements = eval_result["improvements"]
    else:
        # åˆ°é€™ä¸€æ­¥é‚„æ˜¯æ²’æœ‰æ–‡å­—ï¼ˆä¾‹å¦‚è½‰éŒ„å¤±æ•—ï¼‰â†’ ä¸è©•åˆ†ï¼Œåªç´€éŒ„
        score = None
        strengths = ""
        improvements = ""
        eval_result = {
            "score": score,
            "strengths": strengths,
            "improvements": improvements,
        }

    # å¦‚æœæœ‰è½‰éŒ„æ–‡å­—ï¼Œå°±é †ä¾¿å›å‚³çµ¦å‰ç«¯ï¼ˆä¹‹å¾Œä½ å¯ä»¥ç”¨åœ¨ practice é é¢é¡¯ç¤ºï¼‰
    if transcript_text:
        eval_result["transcript"] = transcript_text

    # ---------- å¯«å…¥ session ----------
    log_practice_turn(
        profile_id=req.profile_id,
        question=req.question,
        sample_answer=req.sample_answer,
        bullets=bullets,
        mode=req.mode,
        behavioral_type=req.behavioral_type,
        entry_key=req.entry_key,
        user_answer=req.user_answer,   # é€™è£¡å¯èƒ½æ˜¯ï¼šä½¿ç”¨è€…æ‰“çš„ æˆ– è½‰éŒ„æ–‡å­—
        score=score,
        strengths=strengths,
        improvements=improvements,
        thread_id=req.thread_id,
        is_followup=req.is_followup,
        media_type=media_type,
        media_filename=media_filename,
        media_duration_ms=media_duration_ms,
    )

    return eval_result

class MockNextQuestionRequest(BaseModel):
    profile_id: str
    index: int                 # ç¬¬å¹¾é¡Œï¼ˆ1-basedï¼‰
    session_config: Dict[str, Any]
    prev_answer: Optional[str] = None
    entry_key: Optional[str] = None   # å¦‚æœä½ æƒ³å¼·åˆ¶æŸé¡Œæ˜¯ project


@app.post("/api/mock_next_question")
async def api_mock_next_question(payload: Dict[str, Any]):
    """
    body:
    {
      "session_id": "...",
      "index": 0,         # 0-based
      "seconds_left": 900 # âœ… time mode çš„æ™‚å€™æ‰æœƒå¸¶ï¼Œå–®ä½ï¼šç§’
    }
    """
    session_id = payload.get("session_id")
    index_raw = payload.get("index", 0)
    seconds_left = payload.get("seconds_left")   # âœ… time mode ç”¨

    if session_id is None:
        raise HTTPException(status_code=400, detail="session_id is required")

    try:
        index = int(index_raw)
    except (TypeError, ValueError):
        raise HTTPException(status_code=400, detail="index must be an integer")

    try:
        # âœ… æŠŠç§’æ•¸å‚³çµ¦ mock_interview
        q = mock_interview.get_question_for_index(
            session_id,
            index,
            seconds_left=seconds_left,
        )
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Session not found")

    # ---------- åœ¨é€™è£¡æŠŠ reaction + question åˆä½µ ----------
    # å‡è¨­ mock_interview.get_question_for_index æœƒå›å‚³é¡ä¼¼ï¼š
    # {
    #   "question": "Can you walk me through ...",
    #   "tag": "...",
    #   "reaction": "It's great to hear you're studying at Columbia; ..."
    #   ...
    # }
    reaction_text = (q.get("reaction") or "").strip()
    question_text = (q.get("question") or "").strip()

    if reaction_text and question_text:
        # å…©è¡Œï¼ŒåŒä¸€å€‹ bubbleã€åŒæ¨£å­—é«”
        # å¦‚æœä½ æƒ³åŒä¸€è¡Œå°±æ”¹æˆ f"{reaction_text} {question_text}"
        combined = f"{reaction_text}\n\n{question_text}"
        q["question"] = combined
    elif reaction_text:
        # è¬ä¸€æ²’æœ‰ questionï¼ˆç†è«–ä¸Šä¸æœƒï¼‰ï¼Œè‡³å°‘ä¸è¦ä¸Ÿæ‰ reaction
        q["question"] = reaction_text

    return JSONResponse(q)

    
@app.post("/api/mock_finish")
async def api_mock_finish(meta: str = Form(...)):
    """
    End interview æ™‚å‘¼å«ï¼š
      - meta: JSON å­—ä¸²ï¼Œè‡³å°‘è¦æœ‰ {session_id}
    ä¸å†éœ€è¦æ•´æ®µ mediaï¼Œå› ç‚ºæ¯é¡Œå·²ç¶“ç”¨ /api/mock_answer å­˜å¥½ transcriptã€‚
    """
    import json as _json

    try:
        meta_obj = _json.loads(meta)
    except _json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid meta JSON")

    session_id = meta_obj.get("session_id")
    if not session_id:
        raise HTTPException(status_code=400, detail="session_id is required")

    try:
        report = mock_interview.finalize_mock_session(session_id=session_id)
    except Exception as e:
        print("[api_mock_finish] finalize_mock_session error:", e)
        raise HTTPException(status_code=500, detail="Failed to finalize mock session")

    return {
        "session_id": session_id,
        "overall_score": report.get("overall_score"),
    }

@app.post("/api/mock_answer")
async def api_mock_answer(
    meta: str = Form(...),
    media: UploadFile = File(...),
):
    """
    ä¸€é¡ŒçµæŸæ™‚å‘¼å«ï¼š
      - meta: JSON å­—ä¸²ï¼Œè‡³å°‘åŒ…å« {session_id, index, question_id, question_text}
              ï¼ˆå¦‚æœæœ‰ä½¿ç”¨ realtime transcriptï¼Œæœƒå¤šå¸¶ realtime_transcriptï¼‰
      - media: é€™ä¸€é¡Œçš„éŒ„éŸ³/éŒ„å½± (webm)

    å¾Œç«¯ï¼š
      1) å­˜æª”åˆ° user_data/mock/media/<session_id>_<index>.webm
      2) å„ªå…ˆä½¿ç”¨ realtime_transcriptï¼›è‹¥æ²’æœ‰ï¼Œå†å‘¼å« transcribe_media
      3) ç”¢ç”Ÿä¸€å¥çŸ­åæ‡‰ï¼ˆåƒé¢è©¦å®˜æœƒèªªçš„è©±ï¼‰
      4) å­˜é€² mock session çš„ answersï¼ˆå« reactionã€transcript_sourceï¼‰
      5) åˆ¤æ–·æ˜¯å¦æ’ follow-upï¼ˆä¸ç®—é¡Œæ•¸ï¼‰
    """
    import json

    # -----------------------------
    # parse meta
    # -----------------------------
    try:
        meta_obj = json.loads(meta)
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid meta JSON")

    session_id = meta_obj.get("session_id")
    index = meta_obj.get("index")
    question_id = meta_obj.get("question_id")
    question_text = meta_obj.get("question_text") or ""

    if session_id is None or index is None:
        raise HTTPException(status_code=400, detail="session_id and index are required")

    # -----------------------------
    # 1) save media
    # -----------------------------
    media_dir = mock_interview.MOCK_MEDIA_DIR
    media_dir.mkdir(parents=True, exist_ok=True)

    filename = f"{session_id}_{index}.webm"
    media_path = media_dir / filename

    with media_path.open("wb") as f:
        shutil.copyfileobj(media.file, f)

    # -----------------------------
    # 2) transcriptionï¼šå„ªå…ˆç”¨ realtime_transcript
    # -----------------------------
    # å‰ç«¯å¦‚æœæœ‰ä¸² Realtimeï¼Œå°±åœ¨ meta è£¡å¸¶ä¸Š realtime_transcript
    realtime_text = meta_obj.get("realtime_transcript") or ""
    if not isinstance(realtime_text, str):
        realtime_text = ""
    realtime_text = realtime_text.strip()

    transcript_source = "none"
    transcript_text = ""

    if realtime_text:
        # âœ… æ­£å¸¸æƒ…æ³ï¼šç”¨ Realtime API å·²ç¶“è½‰å¥½çš„æ–‡å­—
        transcript_text = realtime_text
        transcript_source = "realtime"
        print('is working')
    else:
        print('RT not working')
        # ğŸ›Ÿ Fallbackï¼šå¦‚æœæ²’æœ‰ realtimeï¼ˆæˆ–å¤±æ•—ï¼‰ï¼Œæ‰è·‘ batch transcribe
        try:
            transcript_text = transcribe_media(
                media_path,
                language="en",
                prompt="This is a mock interview answer. Please transcribe clearly.",
            )
            transcript_source = "batch"
        except Exception as e:
            print("[api_mock_answer] transcription error:", e)
            transcript_text = ""
            transcript_source = "error"

    # -----------------------------
    # 3) interviewer reactionï¼ˆå…ˆç®—å¥½ï¼‰
    # -----------------------------
    try:
        reaction = mock_interview.generate_interviewer_reaction(
            question_text,
            transcript_text or "",
        )
    except Exception as e:
        print("[api_mock_answer] reaction error:", e)
        reaction = ""

    # -----------------------------
    # 4) write into session.answersï¼ˆåŒ…å« reaction + transcript_sourceï¼‰
    # -----------------------------
    session = mock_interview.load_mock_session(session_id)
    answers = session.get("answers") or []

    # remove previous record of same index
    answers = [a for a in answers if a.get("index") != index]

    answer_obj = {
        "index": index,
        "question_id": question_id,
        "question_text": question_text,
        "transcript": transcript_text or "",
        "reaction": reaction or "",
        "transcript_source": transcript_source,   # ğŸ‘ˆ æ–°å¢ï¼šè¨˜éŒ„ä¾†æºï¼ˆrealtime/batch/errorï¼‰
    }

    answers.append(answer_obj)
    session["answers"] = answers
    mock_interview.save_mock_session(session)

    # -----------------------------
    # 5) try inserting a follow-up question
    # -----------------------------
    try:
        mock_interview._maybe_add_followup_after_answer(
            session_id=session_id,
            answer=answer_obj,
        )
    except Exception as e:
        print("[api_mock_answer] maybe_add_followup error:", e)

    return {
        "status": "ok",
        "index": index,
        "has_transcript": bool(transcript_text),
        "reaction": reaction,
        "transcript": transcript_text or "",
        "transcript_source": transcript_source,
    }

@app.websocket("/ws/mock_realtime")
async def ws_mock_realtime(client_ws: WebSocket):
    await client_ws.accept()
    print("[ws_mock_realtime] client connected")

    if not OPENAI_API_KEY:
        await client_ws.send_text(json.dumps({
            "type": "error",
            "message": "OPENAI_API_KEY is not set on server",
        }))
        await client_ws.close()
        return

    openai_url = "wss://api.openai.com/v1/realtime?intent=transcription"

    session = aiohttp.ClientSession()

    try:
        async with session.ws_connect(
            openai_url,
            headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "openai-beta": "realtime=v1",
            },
        ) as openai_ws:
            print("[ws_mock_realtime] connected to OpenAI Realtime")

            # âœ… æ­£ç¢ºçš„ transcription_session.updateï¼šæ‰€æœ‰è¨­å®šåŒ…åœ¨ "session" è£¡
            await openai_ws.send_json({
                "type": "transcription_session.update",
                "session": {
                    "input_audio_format": "pcm16",
                    "input_audio_transcription": {
                        "model": "whisper-1",
                        "prompt": "",
                        "language": "en",
                    },
                    "turn_detection": {
                        "type": "server_vad",
                        "threshold": 0.5,
                        "prefix_padding_ms": 300,
                        "silence_duration_ms": 500,
                    },
                    "input_audio_noise_reduction": {
                        "type": "near_field",
                    },
                }
            })
            print("[ws_mock_realtime] sent transcription_session.update")

            async def pump_client_to_openai():
                try:
                    async for msg in client_ws.iter_text():
                        try:
                            data = json.loads(msg)
                        except Exception:
                            continue

                        if data.get("type") in (
                            "input_audio_buffer.append",
                            "input_audio_buffer.commit",
                        ):
                            await openai_ws.send_json(data)
                except Exception as e:
                    print("[ws_mock_realtime] client->openai error:", e)

            async def pump_openai_to_client():
                """
                æŠŠ OpenAI ç™¼å›ä¾†çš„ event è£¡çš„æ–‡å­—æŠ“å‡ºä¾†ï¼Œé€æˆï¼š
                  { "type": "transcript", "text": "<å…¨æ–‡æˆ–ç›®å‰ç´¯ç©>" }
                """
                current_text = ""

                async for msg in openai_ws:
                    if msg.type != aiohttp.WSMsgType.TEXT:
                        if msg.type in (aiohttp.WSMsgType.CLOSE, aiohttp.WSMsgType.ERROR):
                            break
                        continue

                    try:
                        event = msg.json()
                    except Exception as e:
                        print("[ws_mock_realtime] parse error:", e)
                        continue

                    etype = event.get("type", "")
                    print("[ws_mock_realtime] OpenAI event:", etype)

                    # === 1) éƒ¨åˆ†æ–‡å­—ï¼ˆæœ‰äº›ç‰ˆæœ¬å« partialï¼Œæœ‰äº›å« deltaï¼‰ ===
                    if etype in (
                        "conversation.item.input_audio_transcription.partial",
                        "conversation.item.input_audio_transcription.delta",
                    ):
                        # ç›®å‰å®˜æ–¹ä¾‹å­æ˜¯ transcript æˆ– delta ç›´æ¥åœ¨é ‚å±¤
                        fragment = (
                            event.get("delta")      # delta ç‰ˆæœ¬
                            or event.get("transcript")  # partial ç‰ˆæœ¬
                            or ""
                        )
                        if fragment:
                            current_text += fragment
                            await client_ws.send_text(json.dumps({
                                "type": "transcript",
                                "text": current_text,
                            }))
                        continue

                    # === 2) å®Œæ•´ä¸€å¥çµæŸ ===
                    if etype == "conversation.item.input_audio_transcription.completed":
                        final_text = event.get("transcript") or ""
                        if final_text:
                            current_text = final_text
                            await client_ws.send_text(json.dumps({
                                "type": "transcript",
                                "text": current_text,
                            }))
                        continue

                    # å…¶ä»–äº‹ä»¶ï¼ˆspeech_started / committed / conversation.item.created ç­‰ï¼‰å…ˆç•¥é
                    # å¦‚æœè¦ debugï¼Œå¯ä»¥æš«æ™‚å°æ•´å€‹ event çœ‹çµæ§‹ï¼š
                    # else:
                    #     print("[ws_mock_realtime] DEBUG EVENT:", json.dumps(event, ensure_ascii=False))

            await asyncio.gather(
                pump_client_to_openai(),
                pump_openai_to_client(),
            )

    except Exception as e:
        print("[ws_mock_realtime] error:", e)
        try:
            await client_ws.send_text(json.dumps({
                "type": "error",
                "message": f"realtime websocket error: {e}",
            }))
        except Exception:
            pass
    finally:
        await session.close()
        try:
            await client_ws.close()
        except Exception:
            pass
        print("[ws_mock_realtime] closed")

@app.get("/mock_media/{session_id}/{index}")
async def get_mock_media(session_id: str, index: int):
    path = mock_interview.MOCK_MEDIA_DIR / f"{session_id}_{index}.webm"
    if not path.exists():
        raise HTTPException(status_code=404, detail="Media not found")
    return FileResponse(path, media_type="video/webm")


# ---------- TTS Request model ----------

class TTSRequest(BaseModel):
    text: str
    session_id: str    # ç”¨ä¾†å¾ mock session è®€ interviewer_profile
# ---------- Voice pool ----------

VOICE_POOLS = {
    "male": ["onyx", "echo"],
    # femaleï¼šåªç•™åå¥³æ€§çš„è²éŸ³
    "female": ["fable", "shimmer", "nova", "coral"],
    # neutralï¼šæ”¾ alloy + ä¸­æ€§
    "neutral": ["alloy", "sage", "ballad", "ash"],
}

ALL_VOICES = list({v for lst in VOICE_POOLS.values() for v in lst})


def pick_voice(gender: str | None) -> str:
    """ä¾ç…§ä½¿ç”¨è€…é¸çš„ gender é¸ä¸€å€‹ voice."""
    if not gender or gender == "auto":
        return random.choice(ALL_VOICES)

    gender = gender.lower()

    # å¦‚æœå‰›å¥½å‚³çš„æ˜¯æŸå€‹ voice åç¨±ï¼Œå°±ç›´æ¥ç”¨
    if gender in ALL_VOICES:
        return gender

    # å¦å‰‡ç•¶æˆ gender key
    if gender in VOICE_POOLS:
        return random.choice(VOICE_POOLS[gender])

    # fallback
    return "alloy"


def combine_style_and_role_for_tts(
    role_desc: str | None,
    style_desc: str | None,
    extra_notes: str | None = None,
) -> str:
    """
    æŠŠ interviewer çš„ role + style + extra notes çµ„æˆçµ¦ TTS çš„ instructionsã€‚
    """
    parts = []

    if role_desc:
        parts.append(f"Speak like this kind of interviewer: {role_desc}.")

    if style_desc:
        parts.append(f"The tone and behavior should match this description: {style_desc}.")

    if extra_notes:
        parts.append(f"Additional interviewer persona notes: {extra_notes}")

    parts.append(
        "Sound like a realistic, professional interviewer in an English job interview. "
        "Be clear and human-like, not robotic."
    )

    return " ".join(parts)



# ---------- API endpoint ----------

@app.post("/api/tts_question")
async def tts_question(req: TTSRequest):
    """
    ç”¨ session_id è®€å– mock session è£¡çš„ interviewer_profileï¼Œ
    æ ¹æ“š gender / role_resolved / style_resolved / extra_notes ä¾†æ±ºå®š voice + instructionsï¼Œ
    ç„¶å¾ŒæŠŠ text è®Šæˆ mp3 å›å‚³ã€‚

    âœ… è²éŸ³åªåœ¨é€™å€‹ session ç¬¬ä¸€æ¬¡ TTS æ™‚æ±ºå®šï¼Œä¹‹å¾Œå…¨éƒ¨æ²¿ç”¨åŒä¸€å€‹ voiceã€‚
    """
    text = (req.text or "").strip()
    if not text:
        raise HTTPException(status_code=400, detail="Empty text")

    # 1) load mock session
    try:
        session = mock_interview.load_mock_session(req.session_id)
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Mock session not found")

    interviewer_profile = session.get("interviewer_profile") or {}

    gender = interviewer_profile.get("gender")               # "male" / "female" / "auto"
    role_desc = interviewer_profile.get("role_resolved")
    style_desc = interviewer_profile.get("style_resolved")
    extra_notes = interviewer_profile.get("extra_notes")
    tts_persona = interviewer_profile.get("tts_persona")

    # 2) æ±ºå®š voiceï¼šå¦‚æœé€™å€‹ session å·²ç¶“æœ‰ tts_voiceï¼Œå°±æ²¿ç”¨ï¼›æ²’æœ‰æ‰æŒ‘ä¸€æ¬¡
    selected_voice = interviewer_profile.get("tts_voice")
    if not selected_voice:
        selected_voice = pick_voice(gender)
        interviewer_profile["tts_voice"] = selected_voice
        session["interviewer_profile"] = interviewer_profile
        # â­ å¯«å›æª”æ¡ˆï¼Œä¹‹å¾Œé€™å€‹ session çš„æ‰€æœ‰é¡Œç›®å°±éƒ½ç”¨åŒä¸€å€‹ voice
        mock_interview.save_mock_session(session)

    # 3) çµ„ instructionsï¼šå„ªå…ˆç”¨ tts_personaï¼Œæ²’æœ‰æ‰è‡ªå·±æ‹¼
    if tts_persona:
        tts_instructions = (
            f"{tts_persona} "
            "Sound like a realistic, professional interviewer in an English job interview. "
            "Be clear and human-like, not robotic."
        )
    else:
        tts_instructions = combine_style_and_role_for_tts(
            role_desc,
            style_desc,
            extra_notes,
        )

    print("[TTS] voice:", selected_voice)
    print("[TTS] instructions:", tts_instructions)

    # 4) å‘¼å« OpenAI TTS
    try:
        with client.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts",
            voice=selected_voice,
            input=text,
            response_format="mp3",
            instructions=tts_instructions,
        ) as response:
            with NamedTemporaryFile(suffix=".mp3") as tmp:
                response.stream_to_file(tmp.name)
                tmp.seek(0)
                audio_bytes = tmp.read()

    except Exception as e:
        print("TTS error:", e)
        raise HTTPException(status_code=500, detail=f"TTS failed: {str(e)}")

    return Response(
        content=audio_bytes,
        media_type="audio/mpeg",
        headers={"Content-Disposition": "inline; filename=tts.mp3"},
    )