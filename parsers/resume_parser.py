# resume_parser.py

import os
import json
import re
import argparse
import pdfplumber


# ======================
#  PDF æ–‡å­—æŠ½å–
# ======================

def extract_pdf_text(pdf_path: str) -> str:
    text = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text.append(page_text)
    return "\n".join(text)


# ======================
#  å”åŠ©åˆ¤æ–·çš„å°å‡½å¼
# ======================

def is_section_header(line: str) -> bool:
    clean = line.strip()
    return clean.isupper() and 3 <= len(clean) <= 40


def is_bullet(line: str) -> bool:
    clean = line.strip()
    return clean.startswith("â€¢") or clean.startswith("- ")


def is_role_title(line: str) -> bool:
    # ä¾ç…§ä½ å±¥æ­·å¸¸è¦‹è·ç¨±é—œéµå­—
    keywords = [
        "Intern", "Assistant", "Research", "Engineer", "Scientist",
        "Developer", "Associate", "Fellow"
    ]
    return any(k in line for k in keywords)


# ======================
#  Experience / Projects è§£æï¼šsection + entry + bullet
# ======================

def parse_resume_entries(text: str):
    """
    è§£æå‡ºç¶“é©—å‹çš„ bulletsï¼Œè¼¸å‡º list of dictï¼š
    {
        "section": "EXPERIENCE" / "PROJECTS",
        "entry": "CAYIN Technology â€” AI Engineering Intern ...",
        "text":  "æŸä¸€æ¢ bullet"
    }
    """
    lines = [l.rstrip() for l in text.split("\n") if l.strip()]

    results = []
    current_section = None
    current_entry = None

    i = 0
    while i < len(lines):
        line = lines[i].strip()

        # 1) SECTION header
        if is_section_header(line):
            current_section = line
            current_entry = None
            i += 1
            continue

        # 2) EXPERIENCE entry: company + role (å…©è¡Œ)
        if (
            current_section == "EXPERIENCE"
            and i + 1 < len(lines)
            and not is_bullet(line)
            and not is_section_header(line)
            and not is_bullet(lines[i+1])
            and is_role_title(lines[i+1])
        ):
            company = line
            role = lines[i+1].strip()
            current_entry = f"{company} â€” {role}"
            i += 2
            continue

        # 2b) PROJECTS entry: ä¸€è¡Œæ¨™é¡Œï¼Œä¸‹ä¸€è¡Œæ˜¯ bullet
        if (
            current_section == "PROJECTS"
            and current_entry is None
            and not is_bullet(line)
            and not is_section_header(line)
            and i + 1 < len(lines)
            and is_bullet(lines[i+1])
        ):
            current_entry = line  # e.g. "Financial Argument Mining with LLMs, NTU Spring 2024"
            i += 1
            continue

        # 3) BULLET + å¤šè¡Œåˆä½µ
        if is_bullet(line):
            bullet = line.lstrip("â€¢- ").strip()
            j = i + 1

            while j < len(lines):
                nxt = lines[j].strip()

                # ä¸‹ä¸€è¡Œæ˜¯æ–°çš„ bullet æˆ– section â†’ çµæŸ
                if is_bullet(nxt) or is_section_header(nxt):
                    break

                # ä¸‹ä¸€è¡Œé•·å¾—åƒæ–°çš„ EXPERIENCE entry â†’ çµæŸ
                if (
                    j + 1 < len(lines)
                    and not is_bullet(nxt)
                    and is_role_title(lines[j+1])
                ):
                    break

                # å…¶ä»–æƒ…æ³ï¼šç•¶ä½œçºŒè¡Œ
                bullet += " " + nxt
                j += 1

            results.append({
                "section": current_section,
                "entry": current_entry,
                "text": bullet
            })

            i = j
            continue

        # 4) å…¶ä»–æ™®é€šè¡Œç•¥é
        i += 1

    return results


# ======================
#  Metadata (EDUCATION / SKILLS / COURSES)
# ======================

def extract_metadata_sections(text: str):
    """
    æŠ½å‡º EDUCATION / SKILLS / COURSES ç­‰ metadata å€å¡Šã€‚
    - EDUCATION / SKILLS ä¾å…¨å¤§å¯«æ¨™é¡Œåˆ†æ®µ
    - åœ¨ EDUCATION å€å¡Šä¸­ï¼Œé¡å¤–æŠŠæ‰€æœ‰ 'Courses:' è¡Œæ”¶é›†åˆ° metadata['COURSES']
    """
    lines = [l.strip() for l in text.split("\n") if l.strip()]
    metadata = {
        "EDUCATION": "",
        "SKILLS": "",
        "COURSES": "",
        "OTHER": ""
    }

    current = None

    for line in lines:
        # å…¨å¤§å¯« section header
        if line.isupper() and len(line) >= 3:
            up = line.upper()

            # ä¸æŠŠ EXPERIENCE/PROJECTS ç´å…¥ metadata
            if up in ["EXPERIENCE", "PROJECTS"]:
                current = None
                continue

            if up in metadata:
                current = up
                continue

            if up in ["EDUCATION", "SKILLS"]:
                current = up
                continue

            current = "OTHER"
            continue

        # åœ¨ EDUCATION å€å¡Šå…§ï¼Œç‰¹æ®ŠæŠ“ Courses: è¡Œ
        if current == "EDUCATION" and line.lower().startswith("courses:"):
            if metadata["COURSES"]:
                metadata["COURSES"] += "\n" + line
            else:
                metadata["COURSES"] = line

        # ä¸€èˆ¬æƒ…æ³ï¼šæ­¤è¡Œæ­¸å±¬ç•¶å‰ section
        if current:
            if metadata[current]:
                metadata[current] += "\n" + line
            else:
                metadata[current] = line

    return metadata


# ======================
#  EDUCATION çµæ§‹åŒ–è§£æ
# ======================

def extract_structured_education(text: str):
    """
    å¾ EDUCATION å€å¡Šä¸­æŠ“å‡ºï¼š
    - school_name
    - degree (å«å¹´é™)
    - gpa
    - courses (list of str)
    å›å‚³ list[dict]ï¼Œæ¯é–“å­¸æ ¡ä¸€å€‹ dictã€‚
    """
    metadata = extract_metadata_sections(text)
    edu_text = metadata.get("EDUCATION", "")

    lines = [l.strip() for l in edu_text.split("\n") if l.strip()]

    schools = []
    current_school = {}

    date_pattern = re.compile(r"(20\d{2}).*(20\d{2}|expected)", re.IGNORECASE)
    gpa_pattern = re.compile(r"GPA\s*([0-9]\.[0-9])", re.IGNORECASE)

    for line in lines:

        # 1) åˆ¤æ–·æ–°å­¸æ ¡ï¼šåŒ…å« University æˆ– NTU
        if "University" in line or "NTU" in line:
            if current_school:
                schools.append(current_school)

            current_school = {
                "school_name": line,
                "degree": None,
                "major": None,   # ç›®å‰å…ˆä¸æ‹† majorï¼Œä¹‹å¾Œå¯ä»¥å†åŠ 
                "location": None,
                "dates": None,
                "gpa": None,
                "courses": []
            }
            continue

        # 2) Degree + dates + GPAï¼ˆä¾‹å¦‚ MS / BS é‚£è¡Œï¼‰
        if "Master" in line or "BS" in line:
            deg_line = line
            current_school["degree"] = deg_line

            m = date_pattern.search(line)
            if m:
                current_school["dates"] = m.group(0)

            gpa_m = gpa_pattern.search(line)
            if gpa_m:
                current_school["gpa"] = gpa_m.group(1)

            continue

        # 3) Courses: è¡Œ
        if line.startswith("Courses:"):
            courses_str = line.replace("Courses:", "").strip()
            current_school["courses"].append(courses_str)
            continue

    if current_school:
        schools.append(current_school)

    return schools


# ======================
#  CLI åŸ·è¡Œå…¥å£
# ======================
def parse_resume_to_bullets(pdf_path: str):
    """
    çµ¦ FastAPI å¾Œç«¯ä½¿ç”¨çš„ä»‹é¢ï¼š
    è¼¸å…¥ PDF è·¯å¾‘ï¼Œå›å‚³ experience/project çš„ bullets listã€‚
    æ ¼å¼ï¼š
    [
      {
        "section": "EXPERIENCE",
        "entry": "CAYIN Technology â€” AI Engineering Intern ...",
        "text": "æŸæ¢ bullet"
      },
      ...
    ]
    """
    # 1) è®€ PDF æ–‡å­—
    raw_text = extract_pdf_text(pdf_path)

    # 2) è§£æç¶“é©—å‹ bullets (EXPERIENCE / PROJECTS)
    entries = parse_resume_entries(raw_text)

    return entries

def parse_resume_all(pdf_path: str):
    """
    çµ¦ FastAPI / å…¶ä»– Python code ç”¨çš„å…¥å£ï¼š
    è¼¸å…¥ä¸€å€‹ PDF è·¯å¾‘ï¼Œå›å‚³ä¸€å€‹ dictï¼ŒåŒ…å«ï¼š
    - entries: EXPERIENCE / PROJECTS çš„ bullets
    - metadata: EDUCATION / SKILLS / COURSES / OTHER
    - education_structured: çµæ§‹åŒ–çš„å­¸æ­·è³‡è¨Š
    """
    # 1) è®€ PDF æ–‡å­—
    raw_text = extract_pdf_text(pdf_path)

    # 2) è§£æç¶“é©—å‹ bullets
    entries = parse_resume_entries(raw_text)

    # 3) è§£æ metadata
    metadata = extract_metadata_sections(raw_text)

    # 4) çµæ§‹åŒ– EDUCATION
    education_structured = extract_structured_education(raw_text)

    return {
        "entries": entries,
        "metadata": metadata,
        "education_structured": education_structured,
        "raw_text": raw_text,
    }

def main():
    parser = argparse.ArgumentParser(
        description="Parse resume PDF and export structured JSON for RAG."
    )
    parser.add_argument(
        "--pdf_path",
        type=str,
        required=True,
        help="Path to the resume PDF file."
    )
    parser.add_argument(
        "--out_dir",
        type=str,
        required=True,
        help="Directory to save parsed JSON outputs."
    )

    args = parser.parse_args()

    pdf_path = args.pdf_path
    out_dir = args.out_dir

    os.makedirs(out_dir, exist_ok=True)

    # ğŸ”¹ æ”¹æˆç”¨ä½ ä¸Šé¢å¯«å¥½çš„é«˜éšå‡½å¼
    result = parse_resume_all(pdf_path)

    entries = result["entries"]
    metadata = result["metadata"]
    education_structured = result["education_structured"]

    # 5) è¼¸å‡º JSON åˆ° out_dir
    entries_path = os.path.join(out_dir, "experience_entries.json")
    metadata_path = os.path.join(out_dir, "metadata.json")
    edu_struct_path = os.path.join(out_dir, "education_structured.json")

    with open(entries_path, "w", encoding="utf-8") as f:
        json.dump(entries, f, ensure_ascii=False, indent=2)

    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    with open(edu_struct_path, "w", encoding="utf-8") as f:
        json.dump(education_structured, f, ensure_ascii=False, indent=2)

    print(f"[OK] Parsed entries saved to: {entries_path}")
    print(f"[OK] Metadata saved to:      {metadata_path}")
    print(f"[OK] Education saved to:     {edu_struct_path}")

if __name__ == "__main__":
    main()
